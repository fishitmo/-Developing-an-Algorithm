{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c4de1a6-11f9-4dea-a93b-baaccd173670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Explicitly disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8b5cf7-f6ab-4d5a-bc9c-aa519dd8175c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\werka\\miniconda3\\envs\\py310\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\werka\\miniconda3\\envs\\py310\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# from keras.utils import np_utils\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow_addons.optimizers import AdamW, Yogi \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71acd049-6c15-49e6-9902-c1b17a5b2448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Enable logging of device placement\n",
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33efbdc-9a35-4e6c-88e6-20106b394de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load and preprocess CIFAR-100 data\n",
    "# (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# # Define the class indices for \"Vehicles 1\"\n",
    "# vehicles_1_indices = [8, 14, 48, 59, 91]\n",
    "\n",
    "# # Filter function to select data by specified class indices\n",
    "# def filter_classes(x_data, y_data, class_indices):\n",
    "#     mask = np.isin(y_data, class_indices).flatten()\n",
    "#     return x_data[mask], y_data[mask]\n",
    "\n",
    "# # Apply the filter function to both training and test sets\n",
    "# x_train_vehicles, y_train_vehicles = filter_classes(x_train, y_train, vehicles_1_indices)\n",
    "# x_test_vehicles, y_test_vehicles = filter_classes(x_test, y_test, vehicles_1_indices)\n",
    "\n",
    "# # Split the training data into training and validation sets\n",
    "# x_train_vehicles, x_val_vehicles, y_train_vehicles, y_val_vehicles = train_test_split(\n",
    "#     x_train_vehicles, y_train_vehicles, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # Print the sizes of each dataset\n",
    "# print(\"Vehicles 1 - Training size:\", len(x_train_vehicles))\n",
    "# print(\"Vehicles 1 - Validation size:\", len(x_val_vehicles))\n",
    "# print(\"Vehicles 1 - Test size:\", len(x_test_vehicles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49102c-0361-42ad-ab5b-e6f408b18e3c",
   "metadata": {},
   "source": [
    "contains the following five classes:\n",
    "\n",
    "Bicycle\n",
    "Bus\n",
    "Motorcycle\n",
    "Pickup truck\n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c952586b-eff0-4587-9e45-92e4608969d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicles 1 - Training dataset size: 2000\n",
      "Vehicles 1 - Validation dataset size: 500\n",
      "Vehicles 1 - Test dataset size: 500\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-100 data\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Normalize the images by scaling pixel values to [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Define the class indices for \"Vehicles 1\"\n",
    "vehicles_1_indices = [8, 14, 48, 59, 91]\n",
    "\n",
    "# Filter function to select data by specified class indices\n",
    "def filter_classes(x_data, y_data, class_indices):\n",
    "    mask = np.isin(y_data, class_indices).flatten()\n",
    "    filtered_x = x_data[mask]\n",
    "    filtered_y = np.array([class_indices.index(label[0]) for label in y_data[mask]])\n",
    "    return filtered_x, filtered_y\n",
    "\n",
    "# Apply the filter function to both training and test sets\n",
    "x_train_vehicles, y_train_vehicles = filter_classes(x_train, y_train, vehicles_1_indices)\n",
    "X_test, y_test = filter_classes(x_test, y_test, vehicles_1_indices)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    x_train_vehicles, y_train_vehicles, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# One-hot encode the class labels for training and validation datasets\n",
    "y_train = to_categorical(y_train, num_classes=len(vehicles_1_indices))\n",
    "y_val = to_categorical(y_val, num_classes=len(vehicles_1_indices))\n",
    "y_test = to_categorical(y_test, num_classes=len(vehicles_1_indices))\n",
    "\n",
    "# Print the sizes of each dataset\n",
    "print(\"Vehicles 1 - Training dataset size:\", len(X_train))\n",
    "print(\"Vehicles 1 - Validation dataset size:\", len(X_val))\n",
    "print(\"Vehicles 1 - Test dataset size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "465d5d93-1594-4291-bf90-8548fee8edd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f945714e-5528-4104-88fb-400e8129f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Usage\n",
    "# preprocessor = CNNDataPreprocessor()\n",
    "# X_train, y_train, X_val, y_val, X_test, y_test = preprocessor.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9ddc93-665f-4415-a07d-8cc41f14d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define reduction percentages\n",
    "# reduction_percentage = 0.7\n",
    "\n",
    "# # Reduce the size of the datasets\n",
    "# X_train, _, y_train, _ = train_test_split(X_train, y_train, test_size=reduction_percentage, random_state=42)\n",
    "# X_val, _, y_val, _ = train_test_split(X_val, y_val, test_size=reduction_percentage, random_state=42)\n",
    "# X_test, _, y_test, _ = train_test_split(X_test, y_test, test_size=reduction_percentage, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3da501-f2ab-48a1-bbe3-37dd540a3473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 32, 32, 3), (500, 32, 32, 3), (500, 32, 32, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0655b009-bd89-434a-bb6d-82a2522294e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NeuralNetworkModel class\n",
    "class NeuralNetworkModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def build_cnn(self, input_shape, num_classes, optimizer):\n",
    "        \"\"\"Build a CNN model compatible with CIFAR-10 data.\"\"\"\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        # self.model.add(Dropout(0.25))\n",
    "        self.model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "        self.model.add(MaxPooling2D((2, 2)))\n",
    "        # self.model.add(Dropout(0.25))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(256, activation='relu'))\n",
    "        # self.model.add(Dropout(0.5))\n",
    "        self.model.add(Dense(num_classes, activation='softmax'))\n",
    "        self.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "        return self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                              validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        y_pred_prob = self.model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9690d45a-c9cc-4e81-80bb-2b7706f8deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the NeuralNetworkModel class\n",
    "# class NeuralNetworkModel:\n",
    "#     def __init__(self):\n",
    "#         self.model = None\n",
    "\n",
    "#     def build_cnn(self, input_shape, num_classes, optimizer):\n",
    "#         \"\"\"Build a CNN model compatible with CIFAR-100 data.\"\"\"\n",
    "#         self.model = Sequential()\n",
    "#         self.model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "#         self.model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "#         self.model.add(Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "#         self.model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "#         self.model.add(Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "#         self.model.add(Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "#         self.model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "#         self.model.add(Flatten())\n",
    "#         self.model.add(Dense(4096, activation='relu'))\n",
    "#         self.model.add(Dropout(0.5))\n",
    "#         self.model.add(Dense(4096, activation='relu'))\n",
    "#         self.model.add(Dropout(0.5))\n",
    "#         self.model.add(Dense(20, activation='softmax'))\n",
    "#         self.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     def train(self, X_train, y_train, X_val, y_val, epochs, batch_size):\n",
    "#         early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "#         reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "#         return self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "#                               validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "#     def evaluate(self, X_test, y_test):\n",
    "#         y_pred_prob = self.model.predict(X_test)\n",
    "#         y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "#         y_true = np.argmax(y_test, axis=1)\n",
    "#         accuracy = accuracy_score(y_true, y_pred)\n",
    "#         precision = precision_score(y_true, y_pred, average='weighted')\n",
    "#         recall = recall_score(y_true, y_pred, average='weighted')\n",
    "#         f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "#         return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45e74b2-8c32-4182-9f5f-8e24a030018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the CIFAR-10 dataset\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# # Normalize images to range [0, 1]\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# # Split the training set into training and validation sets\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "019fd950-c6ef-4612-a68d-04bd22524b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print shapes to verify splits\n",
    "# print(\"Training Set: \", x_train.shape, y_train.shape)\n",
    "# print(\"Validation Set: \", x_val.shape, y_val.shape)\n",
    "# print(\"Test Set: \", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f055553d-3d53-4cdc-bc9f-c59b8ff9bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-hot encoding of the labels\n",
    "# num_classes = 10\n",
    "# y_train = to_categorical(y_train, num_classes)\n",
    "# y_val = to_categorical(y_val, num_classes)\n",
    "# y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9a479a7-0916-45a6-961b-dacb2e3480f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c5f9a5a-3765-416b-9553-bae2f535059a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape[1], x_train.shape[2],x_train.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40af1826-7e15-4326-a508-66849efa25ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with SGD optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5888 - accuracy: 0.2555 - val_loss: 1.5615 - val_accuracy: 0.3160 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.5372 - accuracy: 0.3815 - val_loss: 1.4825 - val_accuracy: 0.4100 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4502 - accuracy: 0.4400 - val_loss: 1.4104 - val_accuracy: 0.3500 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3465 - accuracy: 0.4660 - val_loss: 1.3044 - val_accuracy: 0.4480 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2809 - accuracy: 0.4880 - val_loss: 1.3080 - val_accuracy: 0.4080 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2189 - accuracy: 0.5240 - val_loss: 1.1986 - val_accuracy: 0.5340 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1638 - accuracy: 0.5375 - val_loss: 1.1866 - val_accuracy: 0.5140 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1457 - accuracy: 0.5545 - val_loss: 1.1178 - val_accuracy: 0.5720 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0926 - accuracy: 0.5705 - val_loss: 1.1277 - val_accuracy: 0.5280 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0648 - accuracy: 0.5880 - val_loss: 1.0648 - val_accuracy: 0.5780 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0367 - accuracy: 0.6095 - val_loss: 1.0046 - val_accuracy: 0.6080 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0065 - accuracy: 0.6075 - val_loss: 1.0032 - val_accuracy: 0.6320 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9791 - accuracy: 0.6170 - val_loss: 1.0074 - val_accuracy: 0.6080 - lr: 0.0100\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9480 - accuracy: 0.6385 - val_loss: 1.0736 - val_accuracy: 0.5680 - lr: 0.0100\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9241 - accuracy: 0.6465 - val_loss: 0.9883 - val_accuracy: 0.6100 - lr: 0.0100\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9052 - accuracy: 0.6405 - val_loss: 0.8899 - val_accuracy: 0.6540 - lr: 0.0100\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8816 - accuracy: 0.6785 - val_loss: 1.2591 - val_accuracy: 0.4740 - lr: 0.0100\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8536 - accuracy: 0.6795 - val_loss: 1.0203 - val_accuracy: 0.6160 - lr: 0.0100\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8344 - accuracy: 0.6895 - val_loss: 0.8518 - val_accuracy: 0.6540 - lr: 0.0100\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8162 - accuracy: 0.6980 - val_loss: 0.9369 - val_accuracy: 0.6420 - lr: 0.0100\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7835 - accuracy: 0.7085 - val_loss: 0.9332 - val_accuracy: 0.6220 - lr: 0.0100\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7773 - accuracy: 0.7130 - val_loss: 0.8371 - val_accuracy: 0.6700 - lr: 0.0100\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7388 - accuracy: 0.7310 - val_loss: 0.8344 - val_accuracy: 0.6640 - lr: 0.0100\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7383 - accuracy: 0.7190 - val_loss: 0.8716 - val_accuracy: 0.6580 - lr: 0.0100\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7096 - accuracy: 0.7380 - val_loss: 0.7353 - val_accuracy: 0.7140 - lr: 0.0100\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6757 - accuracy: 0.7550 - val_loss: 0.7776 - val_accuracy: 0.6900 - lr: 0.0100\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.7615 - val_loss: 0.9345 - val_accuracy: 0.6480 - lr: 0.0100\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.7530 - val_loss: 0.6769 - val_accuracy: 0.7400 - lr: 0.0100\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.7580 - val_loss: 0.7951 - val_accuracy: 0.7020 - lr: 0.0100\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.6473 - accuracy: 0.7475 - val_loss: 0.6782 - val_accuracy: 0.7340 - lr: 0.0100\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6048 - accuracy: 0.7760 - val_loss: 0.6681 - val_accuracy: 0.7220 - lr: 0.0100\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.7850 - val_loss: 0.6604 - val_accuracy: 0.7260 - lr: 0.0100\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5973 - accuracy: 0.7780 - val_loss: 0.7329 - val_accuracy: 0.7020 - lr: 0.0100\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5598 - accuracy: 0.8020 - val_loss: 0.7497 - val_accuracy: 0.7280 - lr: 0.0100\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.5618 - accuracy: 0.8005 - val_loss: 0.6133 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.5342 - accuracy: 0.8120 - val_loss: 0.6170 - val_accuracy: 0.7480 - lr: 0.0100\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.8135 - val_loss: 0.6413 - val_accuracy: 0.7640 - lr: 0.0100\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5047 - accuracy: 0.8245 - val_loss: 0.5995 - val_accuracy: 0.7520 - lr: 0.0100\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5094 - accuracy: 0.8225 - val_loss: 0.7102 - val_accuracy: 0.7100 - lr: 0.0100\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.8180 - val_loss: 0.7130 - val_accuracy: 0.7240 - lr: 0.0100\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.8350 - val_loss: 0.7156 - val_accuracy: 0.7260 - lr: 0.0100\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.8540 - val_loss: 0.6233 - val_accuracy: 0.7540 - lr: 0.0050\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8570 - val_loss: 0.6024 - val_accuracy: 0.7420 - lr: 0.0050\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8550 - val_loss: 0.5666 - val_accuracy: 0.7600 - lr: 0.0050\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8645 - val_loss: 0.6553 - val_accuracy: 0.7360 - lr: 0.0050\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8605 - val_loss: 0.5928 - val_accuracy: 0.7540 - lr: 0.0050\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8635 - val_loss: 0.5731 - val_accuracy: 0.7760 - lr: 0.0050\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8735 - val_loss: 0.5633 - val_accuracy: 0.7820 - lr: 0.0025\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8745 - val_loss: 0.5600 - val_accuracy: 0.7680 - lr: 0.0025\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8740 - val_loss: 0.5803 - val_accuracy: 0.7660 - lr: 0.0025\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Training model with SGD_momentum optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.5201 - accuracy: 0.3315 - val_loss: 1.3342 - val_accuracy: 0.5040 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.2071 - accuracy: 0.5095 - val_loss: 0.9938 - val_accuracy: 0.6000 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9747 - accuracy: 0.6165 - val_loss: 0.7934 - val_accuracy: 0.7200 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8328 - accuracy: 0.6825 - val_loss: 0.7511 - val_accuracy: 0.7060 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7093 - accuracy: 0.7370 - val_loss: 0.7733 - val_accuracy: 0.6920 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6367 - accuracy: 0.7735 - val_loss: 0.7051 - val_accuracy: 0.7340 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5380 - accuracy: 0.8065 - val_loss: 0.6256 - val_accuracy: 0.7580 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.5049 - accuracy: 0.8220 - val_loss: 0.6636 - val_accuracy: 0.7500 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4206 - accuracy: 0.8475 - val_loss: 0.5640 - val_accuracy: 0.7780 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8700 - val_loss: 0.6020 - val_accuracy: 0.7620 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2983 - accuracy: 0.8990 - val_loss: 0.5780 - val_accuracy: 0.7800 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2416 - accuracy: 0.9175 - val_loss: 0.6668 - val_accuracy: 0.7620 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9445 - val_loss: 0.5940 - val_accuracy: 0.7940 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.9760 - val_loss: 0.6332 - val_accuracy: 0.7980 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0833 - accuracy: 0.9825 - val_loss: 0.6324 - val_accuracy: 0.8040 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9935 - val_loss: 0.6313 - val_accuracy: 0.8080 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9950 - val_loss: 0.6417 - val_accuracy: 0.8080 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0361 - accuracy: 0.9965 - val_loss: 0.6715 - val_accuracy: 0.8020 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9980 - val_loss: 0.6739 - val_accuracy: 0.8080 - lr: 0.0012\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Training model with Nesterov optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.4436 - accuracy: 0.4015 - val_loss: 1.2446 - val_accuracy: 0.4720 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.1104 - accuracy: 0.5540 - val_loss: 0.9202 - val_accuracy: 0.6760 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8876 - accuracy: 0.6700 - val_loss: 0.9581 - val_accuracy: 0.6140 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7409 - accuracy: 0.7195 - val_loss: 0.8277 - val_accuracy: 0.6640 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6462 - accuracy: 0.7650 - val_loss: 0.7137 - val_accuracy: 0.7120 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5474 - accuracy: 0.8040 - val_loss: 0.6501 - val_accuracy: 0.7440 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.8335 - val_loss: 0.6371 - val_accuracy: 0.7680 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8560 - val_loss: 0.5848 - val_accuracy: 0.7820 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3424 - accuracy: 0.8875 - val_loss: 0.5675 - val_accuracy: 0.7740 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2907 - accuracy: 0.9000 - val_loss: 0.6672 - val_accuracy: 0.7640 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2327 - accuracy: 0.9215 - val_loss: 0.5882 - val_accuracy: 0.7840 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9395 - val_loss: 0.6284 - val_accuracy: 0.7820 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9725 - val_loss: 0.6315 - val_accuracy: 0.8080 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0603 - accuracy: 0.9915 - val_loss: 0.6877 - val_accuracy: 0.7920 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9945 - val_loss: 0.7073 - val_accuracy: 0.7860 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9975 - val_loss: 0.7039 - val_accuracy: 0.7940 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9990 - val_loss: 0.7487 - val_accuracy: 0.7760 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.9990 - val_loss: 0.7350 - val_accuracy: 0.8000 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0189 - accuracy: 0.9990 - val_loss: 0.7502 - val_accuracy: 0.7860 - lr: 0.0012\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Training model with RMSprop optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.4554 - accuracy: 0.3975 - val_loss: 0.9856 - val_accuracy: 0.6440 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.0205 - accuracy: 0.6225 - val_loss: 0.7480 - val_accuracy: 0.7340 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8102 - accuracy: 0.6970 - val_loss: 0.7758 - val_accuracy: 0.6940 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6826 - accuracy: 0.7400 - val_loss: 0.7305 - val_accuracy: 0.7260 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5876 - accuracy: 0.7865 - val_loss: 0.6162 - val_accuracy: 0.7520 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4900 - accuracy: 0.8205 - val_loss: 0.5352 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.8510 - val_loss: 0.5303 - val_accuracy: 0.8320 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.8855 - val_loss: 0.6029 - val_accuracy: 0.8060 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2915 - accuracy: 0.9010 - val_loss: 0.9335 - val_accuracy: 0.7240 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.2288 - accuracy: 0.9160 - val_loss: 0.5449 - val_accuracy: 0.8280 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.9715 - val_loss: 0.6498 - val_accuracy: 0.8140 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0724 - accuracy: 0.9810 - val_loss: 0.5787 - val_accuracy: 0.8300 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0494 - accuracy: 0.9905 - val_loss: 0.6138 - val_accuracy: 0.8260 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9955 - val_loss: 0.6191 - val_accuracy: 0.8360 - lr: 2.5000e-04\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.9985 - val_loss: 0.6162 - val_accuracy: 0.8340 - lr: 2.5000e-04\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9995 - val_loss: 0.7711 - val_accuracy: 0.8100 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.6648 - val_accuracy: 0.8300 - lr: 1.2500e-04\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Training model with Adagrad optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.6017 - accuracy: 0.2755 - val_loss: 1.5865 - val_accuracy: 0.3180 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5839 - accuracy: 0.3375 - val_loss: 1.5683 - val_accuracy: 0.2900 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5676 - accuracy: 0.3595 - val_loss: 1.5491 - val_accuracy: 0.4400 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5498 - accuracy: 0.3995 - val_loss: 1.5293 - val_accuracy: 0.4680 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5280 - accuracy: 0.4330 - val_loss: 1.5023 - val_accuracy: 0.4540 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5003 - accuracy: 0.4355 - val_loss: 1.4815 - val_accuracy: 0.4200 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4730 - accuracy: 0.4340 - val_loss: 1.4364 - val_accuracy: 0.4680 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4392 - accuracy: 0.4635 - val_loss: 1.4017 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4064 - accuracy: 0.4650 - val_loss: 1.3807 - val_accuracy: 0.4960 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3733 - accuracy: 0.4795 - val_loss: 1.3322 - val_accuracy: 0.4920 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3447 - accuracy: 0.4880 - val_loss: 1.3162 - val_accuracy: 0.4360 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3190 - accuracy: 0.4900 - val_loss: 1.2883 - val_accuracy: 0.5320 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2950 - accuracy: 0.5125 - val_loss: 1.2652 - val_accuracy: 0.4980 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2716 - accuracy: 0.5195 - val_loss: 1.2474 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2491 - accuracy: 0.5200 - val_loss: 1.2214 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2283 - accuracy: 0.5210 - val_loss: 1.2219 - val_accuracy: 0.5120 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2122 - accuracy: 0.5395 - val_loss: 1.1842 - val_accuracy: 0.5460 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1904 - accuracy: 0.5510 - val_loss: 1.1866 - val_accuracy: 0.5600 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1799 - accuracy: 0.5470 - val_loss: 1.1799 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1623 - accuracy: 0.5565 - val_loss: 1.1430 - val_accuracy: 0.5760 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1454 - accuracy: 0.5670 - val_loss: 1.1423 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1365 - accuracy: 0.5745 - val_loss: 1.1228 - val_accuracy: 0.5780 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1202 - accuracy: 0.5710 - val_loss: 1.1406 - val_accuracy: 0.5440 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1091 - accuracy: 0.5845 - val_loss: 1.1216 - val_accuracy: 0.5380 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0987 - accuracy: 0.5815 - val_loss: 1.1037 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0894 - accuracy: 0.5845 - val_loss: 1.0837 - val_accuracy: 0.5860 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0726 - accuracy: 0.5950 - val_loss: 1.0937 - val_accuracy: 0.6080 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0616 - accuracy: 0.6095 - val_loss: 1.0956 - val_accuracy: 0.5720 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0558 - accuracy: 0.5995 - val_loss: 1.0676 - val_accuracy: 0.6000 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0427 - accuracy: 0.6085 - val_loss: 1.0806 - val_accuracy: 0.5660 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0330 - accuracy: 0.6130 - val_loss: 1.0856 - val_accuracy: 0.5980 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0253 - accuracy: 0.6225 - val_loss: 1.0760 - val_accuracy: 0.5800 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0122 - accuracy: 0.6295 - val_loss: 1.0236 - val_accuracy: 0.6200 - lr: 5.0000e-04\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0052 - accuracy: 0.6355 - val_loss: 1.0222 - val_accuracy: 0.6160 - lr: 5.0000e-04\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9991 - accuracy: 0.6335 - val_loss: 1.0163 - val_accuracy: 0.6220 - lr: 5.0000e-04\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9959 - accuracy: 0.6280 - val_loss: 1.0118 - val_accuracy: 0.6200 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9913 - accuracy: 0.6390 - val_loss: 1.0102 - val_accuracy: 0.6260 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9885 - accuracy: 0.6300 - val_loss: 1.0073 - val_accuracy: 0.6300 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9832 - accuracy: 0.6375 - val_loss: 1.0026 - val_accuracy: 0.6180 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9796 - accuracy: 0.6415 - val_loss: 0.9980 - val_accuracy: 0.6180 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9757 - accuracy: 0.6460 - val_loss: 1.0006 - val_accuracy: 0.6260 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9708 - accuracy: 0.6475 - val_loss: 0.9968 - val_accuracy: 0.6260 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9670 - accuracy: 0.6440 - val_loss: 0.9880 - val_accuracy: 0.6320 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9620 - accuracy: 0.6535 - val_loss: 0.9874 - val_accuracy: 0.6360 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9594 - accuracy: 0.6500 - val_loss: 0.9835 - val_accuracy: 0.6320 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9558 - accuracy: 0.6520 - val_loss: 0.9765 - val_accuracy: 0.6280 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9502 - accuracy: 0.6505 - val_loss: 0.9842 - val_accuracy: 0.6300 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9486 - accuracy: 0.6625 - val_loss: 0.9762 - val_accuracy: 0.6280 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9459 - accuracy: 0.6595 - val_loss: 0.9677 - val_accuracy: 0.6320 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9429 - accuracy: 0.6565 - val_loss: 0.9631 - val_accuracy: 0.6320 - lr: 5.0000e-04\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Training model with Adadelta optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6149 - accuracy: 0.1920 - val_loss: 1.6137 - val_accuracy: 0.1700 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.6113 - accuracy: 0.2020 - val_loss: 1.6095 - val_accuracy: 0.2040 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.6078 - accuracy: 0.2245 - val_loss: 1.6056 - val_accuracy: 0.2320 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.6047 - accuracy: 0.2520 - val_loss: 1.6019 - val_accuracy: 0.2660 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.6018 - accuracy: 0.2560 - val_loss: 1.5986 - val_accuracy: 0.2920 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.5991 - accuracy: 0.2700 - val_loss: 1.5954 - val_accuracy: 0.3040 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.5964 - accuracy: 0.2755 - val_loss: 1.5922 - val_accuracy: 0.3040 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5938 - accuracy: 0.2955 - val_loss: 1.5893 - val_accuracy: 0.3240 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5913 - accuracy: 0.2920 - val_loss: 1.5866 - val_accuracy: 0.3380 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.5890 - accuracy: 0.2940 - val_loss: 1.5840 - val_accuracy: 0.3460 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.5866 - accuracy: 0.2980 - val_loss: 1.5815 - val_accuracy: 0.3720 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.5843 - accuracy: 0.3260 - val_loss: 1.5790 - val_accuracy: 0.3680 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.5820 - accuracy: 0.3425 - val_loss: 1.5765 - val_accuracy: 0.3740 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.5797 - accuracy: 0.3315 - val_loss: 1.5741 - val_accuracy: 0.3860 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.5774 - accuracy: 0.3495 - val_loss: 1.5716 - val_accuracy: 0.4040 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.5750 - accuracy: 0.3545 - val_loss: 1.5691 - val_accuracy: 0.4140 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.5726 - accuracy: 0.3780 - val_loss: 1.5665 - val_accuracy: 0.4180 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.5701 - accuracy: 0.3835 - val_loss: 1.5639 - val_accuracy: 0.4220 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.5675 - accuracy: 0.3865 - val_loss: 1.5613 - val_accuracy: 0.4240 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 1.5649 - accuracy: 0.4055 - val_loss: 1.5587 - val_accuracy: 0.4300 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 1.5624 - accuracy: 0.4170 - val_loss: 1.5560 - val_accuracy: 0.4280 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 4s 55ms/step - loss: 1.5598 - accuracy: 0.4295 - val_loss: 1.5535 - val_accuracy: 0.4320 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 4s 59ms/step - loss: 1.5573 - accuracy: 0.4280 - val_loss: 1.5509 - val_accuracy: 0.4420 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 1.5548 - accuracy: 0.4375 - val_loss: 1.5484 - val_accuracy: 0.4440 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.5522 - accuracy: 0.4485 - val_loss: 1.5458 - val_accuracy: 0.4580 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.5497 - accuracy: 0.4430 - val_loss: 1.5433 - val_accuracy: 0.4640 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.5473 - accuracy: 0.4565 - val_loss: 1.5409 - val_accuracy: 0.4880 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.5448 - accuracy: 0.4680 - val_loss: 1.5384 - val_accuracy: 0.4980 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 1.5423 - accuracy: 0.4720 - val_loss: 1.5357 - val_accuracy: 0.5040 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 1.5398 - accuracy: 0.4835 - val_loss: 1.5332 - val_accuracy: 0.5140 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.5372 - accuracy: 0.4825 - val_loss: 1.5307 - val_accuracy: 0.5200 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5347 - accuracy: 0.4895 - val_loss: 1.5281 - val_accuracy: 0.5180 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5322 - accuracy: 0.4980 - val_loss: 1.5254 - val_accuracy: 0.5320 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5296 - accuracy: 0.5000 - val_loss: 1.5228 - val_accuracy: 0.5360 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 1.5270 - accuracy: 0.5205 - val_loss: 1.5202 - val_accuracy: 0.5340 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.5244 - accuracy: 0.5175 - val_loss: 1.5175 - val_accuracy: 0.5360 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.5218 - accuracy: 0.5205 - val_loss: 1.5148 - val_accuracy: 0.5400 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 1.5191 - accuracy: 0.5250 - val_loss: 1.5120 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 1.5164 - accuracy: 0.5215 - val_loss: 1.5092 - val_accuracy: 0.5380 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.5136 - accuracy: 0.5310 - val_loss: 1.5065 - val_accuracy: 0.5440 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.5108 - accuracy: 0.5340 - val_loss: 1.5036 - val_accuracy: 0.5440 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 1.5079 - accuracy: 0.5315 - val_loss: 1.5006 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 1.5050 - accuracy: 0.5320 - val_loss: 1.4976 - val_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.5020 - accuracy: 0.5395 - val_loss: 1.4946 - val_accuracy: 0.5540 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 2s 23ms/step - loss: 1.4990 - accuracy: 0.5430 - val_loss: 1.4916 - val_accuracy: 0.5480 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 1.4960 - accuracy: 0.5435 - val_loss: 1.4886 - val_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.4930 - accuracy: 0.5440 - val_loss: 1.4855 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.4900 - accuracy: 0.5520 - val_loss: 1.4825 - val_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4870 - accuracy: 0.5435 - val_loss: 1.4795 - val_accuracy: 0.5500 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.4840 - accuracy: 0.5365 - val_loss: 1.4765 - val_accuracy: 0.5540 - lr: 0.0010\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "Training model with Adam optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.1878 - accuracy: 0.5230 - val_loss: 0.8302 - val_accuracy: 0.7000 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.7849 - accuracy: 0.7120 - val_loss: 0.6634 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.6457 - accuracy: 0.7590 - val_loss: 0.6237 - val_accuracy: 0.7620 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.5497 - accuracy: 0.8110 - val_loss: 0.5472 - val_accuracy: 0.7880 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.5103 - accuracy: 0.8225 - val_loss: 0.6241 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.4128 - accuracy: 0.8485 - val_loss: 0.5125 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.3551 - accuracy: 0.8715 - val_loss: 0.6806 - val_accuracy: 0.7560 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.3002 - accuracy: 0.8940 - val_loss: 0.5054 - val_accuracy: 0.8040 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.2408 - accuracy: 0.9205 - val_loss: 0.5221 - val_accuracy: 0.8240 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1823 - accuracy: 0.9435 - val_loss: 0.6032 - val_accuracy: 0.8100 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 0.1217 - accuracy: 0.9665 - val_loss: 0.5995 - val_accuracy: 0.8240 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.0642 - accuracy: 0.9870 - val_loss: 0.5234 - val_accuracy: 0.8400 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.0493 - accuracy: 0.9915 - val_loss: 0.5497 - val_accuracy: 0.8440 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0380 - accuracy: 0.9945 - val_loss: 0.5853 - val_accuracy: 0.8420 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0255 - accuracy: 0.9975 - val_loss: 0.5803 - val_accuracy: 0.8440 - lr: 2.5000e-04\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.0207 - accuracy: 0.9990 - val_loss: 0.6121 - val_accuracy: 0.8420 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.0182 - accuracy: 0.9990 - val_loss: 0.6272 - val_accuracy: 0.8320 - lr: 2.5000e-04\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.0158 - accuracy: 0.9995 - val_loss: 0.6259 - val_accuracy: 0.8400 - lr: 1.2500e-04\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "Training model with AMSGrad optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 3s 27ms/step - loss: 1.2730 - accuracy: 0.4555 - val_loss: 0.9217 - val_accuracy: 0.6400 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.8669 - accuracy: 0.6690 - val_loss: 0.6813 - val_accuracy: 0.7540 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7312 - accuracy: 0.7300 - val_loss: 0.6731 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.6097 - accuracy: 0.7700 - val_loss: 0.5134 - val_accuracy: 0.8060 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.4961 - accuracy: 0.8185 - val_loss: 0.5560 - val_accuracy: 0.7960 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 31ms/step - loss: 0.4119 - accuracy: 0.8540 - val_loss: 0.5426 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 0.3919 - accuracy: 0.8620 - val_loss: 0.5130 - val_accuracy: 0.8040 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.3107 - accuracy: 0.8895 - val_loss: 0.5335 - val_accuracy: 0.8080 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.2557 - accuracy: 0.9200 - val_loss: 0.4862 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.1897 - accuracy: 0.9380 - val_loss: 0.5343 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.1634 - accuracy: 0.9480 - val_loss: 0.5407 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.1051 - accuracy: 0.9720 - val_loss: 0.5399 - val_accuracy: 0.8220 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 0.0588 - accuracy: 0.9880 - val_loss: 0.5488 - val_accuracy: 0.8160 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0405 - accuracy: 0.9935 - val_loss: 0.5569 - val_accuracy: 0.8220 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0312 - accuracy: 0.9955 - val_loss: 0.6161 - val_accuracy: 0.8260 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 2s 31ms/step - loss: 0.0222 - accuracy: 0.9985 - val_loss: 0.5842 - val_accuracy: 0.8300 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0183 - accuracy: 0.9990 - val_loss: 0.5854 - val_accuracy: 0.8300 - lr: 2.5000e-04\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 0.0167 - accuracy: 0.9985 - val_loss: 0.5990 - val_accuracy: 0.8260 - lr: 2.5000e-04\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.5968 - val_accuracy: 0.8320 - lr: 1.2500e-04\n",
      "16/16 [==============================] - 0s 5ms/step\n",
      "Training model with AdamW optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.2027 - accuracy: 0.5225 - val_loss: 0.8826 - val_accuracy: 0.6460 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.7883 - accuracy: 0.7095 - val_loss: 0.6674 - val_accuracy: 0.7560 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.6199 - accuracy: 0.7740 - val_loss: 0.6233 - val_accuracy: 0.7540 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.5269 - accuracy: 0.8105 - val_loss: 0.5751 - val_accuracy: 0.7900 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.4638 - accuracy: 0.8385 - val_loss: 0.6674 - val_accuracy: 0.7380 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.4154 - accuracy: 0.8575 - val_loss: 0.6197 - val_accuracy: 0.7640 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.3362 - accuracy: 0.8855 - val_loss: 0.4897 - val_accuracy: 0.8220 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.2782 - accuracy: 0.8990 - val_loss: 0.4987 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.2101 - accuracy: 0.9340 - val_loss: 0.5303 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.1436 - accuracy: 0.9530 - val_loss: 0.5614 - val_accuracy: 0.7940 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0974 - accuracy: 0.9795 - val_loss: 0.5169 - val_accuracy: 0.8400 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.0626 - accuracy: 0.9910 - val_loss: 0.5269 - val_accuracy: 0.8380 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0497 - accuracy: 0.9900 - val_loss: 0.5468 - val_accuracy: 0.8200 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0378 - accuracy: 0.9960 - val_loss: 0.5449 - val_accuracy: 0.8380 - lr: 2.5000e-04\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.0326 - accuracy: 0.9975 - val_loss: 0.5523 - val_accuracy: 0.8200 - lr: 2.5000e-04\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 0.0323 - accuracy: 0.9955 - val_loss: 0.5426 - val_accuracy: 0.8360 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0280 - accuracy: 0.9990 - val_loss: 0.5270 - val_accuracy: 0.8380 - lr: 1.2500e-04\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "Training model with Yogi optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 3s 28ms/step - loss: 1.5166 - accuracy: 0.3500 - val_loss: 1.4948 - val_accuracy: 0.3700 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 1.1038 - accuracy: 0.5570 - val_loss: 0.9081 - val_accuracy: 0.6440 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.9078 - accuracy: 0.6565 - val_loss: 0.9024 - val_accuracy: 0.6540 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.7627 - accuracy: 0.7145 - val_loss: 0.7608 - val_accuracy: 0.7100 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.6766 - accuracy: 0.7555 - val_loss: 0.6984 - val_accuracy: 0.7100 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.5609 - accuracy: 0.7860 - val_loss: 0.6228 - val_accuracy: 0.7400 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 0.4140 - accuracy: 0.8520 - val_loss: 0.6622 - val_accuracy: 0.7600 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.3728 - accuracy: 0.8545 - val_loss: 0.7485 - val_accuracy: 0.7480 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.3208 - accuracy: 0.8870 - val_loss: 0.9545 - val_accuracy: 0.7260 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.2029 - accuracy: 0.9310 - val_loss: 0.7177 - val_accuracy: 0.7760 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.0763 - accuracy: 0.9835 - val_loss: 0.7893 - val_accuracy: 0.8120 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.0292 - accuracy: 0.9930 - val_loss: 0.9344 - val_accuracy: 0.8020 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.0127 - accuracy: 0.9990 - val_loss: 0.9252 - val_accuracy: 0.8060 - lr: 0.0025\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.9887 - val_accuracy: 0.8020 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.7960 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.7980 - lr: 0.0012\n",
      "16/16 [==============================] - 0s 7ms/step\n",
      "Training model with Nadam optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 3s 36ms/step - loss: 1.2665 - accuracy: 0.4740 - val_loss: 1.6641 - val_accuracy: 0.4100 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 0.8052 - accuracy: 0.7085 - val_loss: 0.6785 - val_accuracy: 0.7240 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 0.6222 - accuracy: 0.7790 - val_loss: 0.6204 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 0.5079 - accuracy: 0.8130 - val_loss: 0.6619 - val_accuracy: 0.7560 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 33ms/step - loss: 0.4145 - accuracy: 0.8470 - val_loss: 0.5028 - val_accuracy: 0.8040 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 0.3187 - accuracy: 0.8790 - val_loss: 1.1081 - val_accuracy: 0.6180 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 0.2818 - accuracy: 0.9025 - val_loss: 0.5270 - val_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 0.1900 - accuracy: 0.9355 - val_loss: 0.5219 - val_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 0.0871 - accuracy: 0.9805 - val_loss: 0.5122 - val_accuracy: 0.8200 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 0.0557 - accuracy: 0.9900 - val_loss: 0.5462 - val_accuracy: 0.8220 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.0411 - accuracy: 0.9925 - val_loss: 0.5262 - val_accuracy: 0.8400 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 0.0272 - accuracy: 0.9980 - val_loss: 0.5454 - val_accuracy: 0.8360 - lr: 2.5000e-04\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 2s 31ms/step - loss: 0.0229 - accuracy: 0.9980 - val_loss: 0.5600 - val_accuracy: 0.8280 - lr: 2.5000e-04\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 0.0198 - accuracy: 0.9995 - val_loss: 0.5652 - val_accuracy: 0.8160 - lr: 2.5000e-04\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 0.0162 - accuracy: 0.9990 - val_loss: 0.5658 - val_accuracy: 0.8320 - lr: 1.2500e-04\n",
      "16/16 [==============================] - 0s 2ms/step\n",
      "Training model with Adamax optimizer...\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.3858 - accuracy: 0.4485 - val_loss: 1.1406 - val_accuracy: 0.5860 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.9659 - accuracy: 0.6525 - val_loss: 0.8517 - val_accuracy: 0.6880 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.8145 - accuracy: 0.7105 - val_loss: 0.7670 - val_accuracy: 0.7180 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.6778 - accuracy: 0.7520 - val_loss: 0.6645 - val_accuracy: 0.7620 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.6286 - accuracy: 0.7680 - val_loss: 0.6191 - val_accuracy: 0.7560 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.5847 - accuracy: 0.7970 - val_loss: 0.6278 - val_accuracy: 0.7680 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 0.5256 - accuracy: 0.8085 - val_loss: 0.5664 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.5021 - accuracy: 0.8195 - val_loss: 0.5601 - val_accuracy: 0.7760 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.4512 - accuracy: 0.8405 - val_loss: 0.5160 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8410 - val_loss: 0.5051 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.4074 - accuracy: 0.8650 - val_loss: 0.6218 - val_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 0.3840 - accuracy: 0.8685 - val_loss: 0.4844 - val_accuracy: 0.8220 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.3434 - accuracy: 0.8830 - val_loss: 0.5183 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.3211 - accuracy: 0.8940 - val_loss: 0.4802 - val_accuracy: 0.8240 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.2957 - accuracy: 0.8980 - val_loss: 0.5234 - val_accuracy: 0.8060 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 0.2775 - accuracy: 0.9075 - val_loss: 0.4771 - val_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 0.2476 - accuracy: 0.9195 - val_loss: 0.4889 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 1s 24ms/step - loss: 0.2186 - accuracy: 0.9345 - val_loss: 0.4970 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 0.2255 - accuracy: 0.9235 - val_loss: 0.4916 - val_accuracy: 0.8240 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 2s 26ms/step - loss: 0.1655 - accuracy: 0.9555 - val_loss: 0.4729 - val_accuracy: 0.8340 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1564 - accuracy: 0.9545 - val_loss: 0.4634 - val_accuracy: 0.8280 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 0.1458 - accuracy: 0.9610 - val_loss: 0.5450 - val_accuracy: 0.8240 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 1s 22ms/step - loss: 0.1318 - accuracy: 0.9685 - val_loss: 0.4903 - val_accuracy: 0.8280 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.1280 - accuracy: 0.9720 - val_loss: 0.4694 - val_accuracy: 0.8400 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.1113 - accuracy: 0.9765 - val_loss: 0.5025 - val_accuracy: 0.8260 - lr: 2.5000e-04\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1021 - accuracy: 0.9815 - val_loss: 0.4749 - val_accuracy: 0.8340 - lr: 2.5000e-04\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0995 - accuracy: 0.9825 - val_loss: 0.4861 - val_accuracy: 0.8340 - lr: 2.5000e-04\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 1s 23ms/step - loss: 0.0917 - accuracy: 0.9850 - val_loss: 0.4919 - val_accuracy: 0.8340 - lr: 1.2500e-04\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 0.0889 - accuracy: 0.9845 - val_loss: 0.4727 - val_accuracy: 0.8300 - lr: 1.2500e-04\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 2s 24ms/step - loss: 0.0857 - accuracy: 0.9865 - val_loss: 0.4838 - val_accuracy: 0.8300 - lr: 1.2500e-04\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 0.0819 - accuracy: 0.9875 - val_loss: 0.4808 - val_accuracy: 0.8340 - lr: 6.2500e-05\n",
      "16/16 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# List of optimizers to test for NN\n",
    "optimizers = {\n",
    "    'SGD': SGD(),\n",
    "    'SGD_momentum': SGD(momentum=0.9),\n",
    "    'Nesterov': SGD(momentum=0.9, nesterov=True),\n",
    "    'RMSprop': tf.keras.optimizers.RMSprop(),\n",
    "    'Adagrad': tf.keras.optimizers.Adagrad(),\n",
    "    'Adadelta': tf.keras.optimizers.Adadelta(),\n",
    "    'Adam': Adam(),\n",
    "    'AMSGrad': Adam(amsgrad=True),\n",
    "    'AdamW': AdamW(weight_decay=1e-4),\n",
    "    'Yogi': Yogi(),\n",
    "    'Nadam': tf.keras.optimizers.Nadam(),\n",
    "    'Adamax': tf.keras.optimizers.Adamax()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "neural_network_model = NeuralNetworkModel()\n",
    "\n",
    "for name, optimizer in optimizers.items():\n",
    "    print(f\"Training model with {name} optimizer...\")\n",
    "    neural_network_model = NeuralNetworkModel()\n",
    "    # neural_network_model.build_ann(input_shape=(X_train.shape[1], X_train.shape[2]), optimizer=optimizer)\n",
    "    neural_network_model.build_cnn(input_shape=(X_train.shape[1], X_train.shape[2],X_train.shape[3]), num_classes=5, optimizer=optimizer)\n",
    "    start_time = time.time()\n",
    "    history = neural_network_model.train(X_train, y_train, X_val, y_val, epochs=50, batch_size=32)\n",
    "    end_time = time.time()\n",
    "    test_accuracy, precision, recall, f1 = neural_network_model.evaluate(X_test, y_test)\n",
    "    training_time = end_time - start_time\n",
    "    convergence_speed = len(history.history['loss'])\n",
    "    results[name] = {\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'convergence_speed': convergence_speed,\n",
    "        'training_time': training_time,\n",
    "        'history': history\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a569ab-daf0-416e-bfd3-ea134d207bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "SGD: Test Accuracy - 0.7920, Precision - 0.8009, Recall - 0.7920, F1-score - 0.7936, Convergence Speed - 50 epochs, Training Time - 21.31 seconds\n",
      "SGD_momentum: Test Accuracy - 0.7860, Precision - 0.7975, Recall - 0.7860, F1-score - 0.7820, Convergence Speed - 19 epochs, Training Time - 8.75 seconds\n",
      "Nesterov: Test Accuracy - 0.7900, Precision - 0.8037, Recall - 0.7900, F1-score - 0.7908, Convergence Speed - 19 epochs, Training Time - 8.45 seconds\n",
      "RMSprop: Test Accuracy - 0.7920, Precision - 0.7989, Recall - 0.7920, F1-score - 0.7872, Convergence Speed - 17 epochs, Training Time - 9.13 seconds\n",
      "Adagrad: Test Accuracy - 0.6600, Precision - 0.6615, Recall - 0.6600, F1-score - 0.6596, Convergence Speed - 50 epochs, Training Time - 22.21 seconds\n",
      "Adadelta: Test Accuracy - 0.5420, Precision - 0.5922, Recall - 0.5420, F1-score - 0.5263, Convergence Speed - 50 epochs, Training Time - 61.56 seconds\n",
      "Adam: Test Accuracy - 0.8360, Precision - 0.8377, Recall - 0.8360, F1-score - 0.8352, Convergence Speed - 18 epochs, Training Time - 22.85 seconds\n",
      "AMSGrad: Test Accuracy - 0.8200, Precision - 0.8320, Recall - 0.8200, F1-score - 0.8218, Convergence Speed - 19 epochs, Training Time - 34.66 seconds\n",
      "AdamW: Test Accuracy - 0.8300, Precision - 0.8357, Recall - 0.8300, F1-score - 0.8294, Convergence Speed - 17 epochs, Training Time - 22.95 seconds\n",
      "Yogi: Test Accuracy - 0.7720, Precision - 0.7754, Recall - 0.7720, F1-score - 0.7690, Convergence Speed - 16 epochs, Training Time - 26.49 seconds\n",
      "Nadam: Test Accuracy - 0.8180, Precision - 0.8325, Recall - 0.8180, F1-score - 0.8196, Convergence Speed - 15 epochs, Training Time - 28.63 seconds\n",
      "Adamax: Test Accuracy - 0.8540, Precision - 0.8536, Recall - 0.8540, F1-score - 0.8535, Convergence Speed - 31 epochs, Training Time - 43.28 seconds\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nResults:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}: Test Accuracy - {result['test_accuracy']:.4f}, \"\n",
    "          f\"Precision - {result['precision']:.4f}, \"\n",
    "          f\"Recall - {result['recall']:.4f}, \"\n",
    "          f\"F1-score - {result['f1_score']:.4f}, \"\n",
    "          f\"Convergence Speed - {result['convergence_speed']} epochs, \"\n",
    "          f\"Training Time - {result['training_time']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd2cdf89-12ae-4cf5-bc1e-ef28884aeab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Size</th>\n",
       "      <th>Number of Features</th>\n",
       "      <th>Target Feature Type</th>\n",
       "      <th>Neural Network Architecture</th>\n",
       "      <th>Optimization Method</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Convergence Speed</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.800877</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.793646</td>\n",
       "      <td>50</td>\n",
       "      <td>21.308368</td>\n",
       "      <td>1.588817</td>\n",
       "      <td>1.561547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>SGD_momentum</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.797451</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.781968</td>\n",
       "      <td>19</td>\n",
       "      <td>8.751369</td>\n",
       "      <td>1.520100</td>\n",
       "      <td>1.334190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Nesterov</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.803653</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.790785</td>\n",
       "      <td>19</td>\n",
       "      <td>8.447104</td>\n",
       "      <td>1.443611</td>\n",
       "      <td>1.244631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.798851</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.787183</td>\n",
       "      <td>17</td>\n",
       "      <td>9.125859</td>\n",
       "      <td>1.455447</td>\n",
       "      <td>0.985581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.661531</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.659627</td>\n",
       "      <td>50</td>\n",
       "      <td>22.207061</td>\n",
       "      <td>1.601670</td>\n",
       "      <td>1.586506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Adadelta</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.592218</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.526297</td>\n",
       "      <td>50</td>\n",
       "      <td>61.558113</td>\n",
       "      <td>1.614892</td>\n",
       "      <td>1.613740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.837735</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.835225</td>\n",
       "      <td>18</td>\n",
       "      <td>22.846334</td>\n",
       "      <td>1.187840</td>\n",
       "      <td>0.830211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AMSGrad</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.832020</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.821763</td>\n",
       "      <td>19</td>\n",
       "      <td>34.658046</td>\n",
       "      <td>1.273012</td>\n",
       "      <td>0.921692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>AdamW</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.835728</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.829367</td>\n",
       "      <td>17</td>\n",
       "      <td>22.946294</td>\n",
       "      <td>1.202680</td>\n",
       "      <td>0.882634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Yogi</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.775364</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.769003</td>\n",
       "      <td>16</td>\n",
       "      <td>26.494704</td>\n",
       "      <td>1.516635</td>\n",
       "      <td>1.494814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Nadam</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.832542</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.819560</td>\n",
       "      <td>15</td>\n",
       "      <td>28.625192</td>\n",
       "      <td>1.266488</td>\n",
       "      <td>1.664139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vehicle</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>float32</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Adamax</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.853605</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.853490</td>\n",
       "      <td>31</td>\n",
       "      <td>43.284580</td>\n",
       "      <td>1.385833</td>\n",
       "      <td>1.140645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Name  Data Size  Number of Features Target Feature Type  \\\n",
       "0    Vehicle       2000                  32             float32   \n",
       "1    Vehicle       2000                  32             float32   \n",
       "2    Vehicle       2000                  32             float32   \n",
       "3    Vehicle       2000                  32             float32   \n",
       "4    Vehicle       2000                  32             float32   \n",
       "5    Vehicle       2000                  32             float32   \n",
       "6    Vehicle       2000                  32             float32   \n",
       "7    Vehicle       2000                  32             float32   \n",
       "8    Vehicle       2000                  32             float32   \n",
       "9    Vehicle       2000                  32             float32   \n",
       "10   Vehicle       2000                  32             float32   \n",
       "11   Vehicle       2000                  32             float32   \n",
       "\n",
       "   Neural Network Architecture Optimization Method  Test Accuracy  Precision  \\\n",
       "0                          CNN                 SGD          0.792   0.800877   \n",
       "1                          CNN        SGD_momentum          0.786   0.797451   \n",
       "2                          CNN            Nesterov          0.790   0.803653   \n",
       "3                          CNN             RMSprop          0.792   0.798851   \n",
       "4                          CNN             Adagrad          0.660   0.661531   \n",
       "5                          CNN            Adadelta          0.542   0.592218   \n",
       "6                          CNN                Adam          0.836   0.837735   \n",
       "7                          CNN             AMSGrad          0.820   0.832020   \n",
       "8                          CNN               AdamW          0.830   0.835728   \n",
       "9                          CNN                Yogi          0.772   0.775364   \n",
       "10                         CNN               Nadam          0.818   0.832542   \n",
       "11                         CNN              Adamax          0.854   0.853605   \n",
       "\n",
       "    Recall  F1-score  Convergence Speed  Training Time  Training Loss  \\\n",
       "0    0.792  0.793646                 50      21.308368       1.588817   \n",
       "1    0.786  0.781968                 19       8.751369       1.520100   \n",
       "2    0.790  0.790785                 19       8.447104       1.443611   \n",
       "3    0.792  0.787183                 17       9.125859       1.455447   \n",
       "4    0.660  0.659627                 50      22.207061       1.601670   \n",
       "5    0.542  0.526297                 50      61.558113       1.614892   \n",
       "6    0.836  0.835225                 18      22.846334       1.187840   \n",
       "7    0.820  0.821763                 19      34.658046       1.273012   \n",
       "8    0.830  0.829367                 17      22.946294       1.202680   \n",
       "9    0.772  0.769003                 16      26.494704       1.516635   \n",
       "10   0.818  0.819560                 15      28.625192       1.266488   \n",
       "11   0.854  0.853490                 31      43.284580       1.385833   \n",
       "\n",
       "    Validation Loss  \n",
       "0          1.561547  \n",
       "1          1.334190  \n",
       "2          1.244631  \n",
       "3          0.985581  \n",
       "4          1.586506  \n",
       "5          1.613740  \n",
       "6          0.830211  \n",
       "7          0.921692  \n",
       "8          0.882634  \n",
       "9          1.494814  \n",
       "10         1.664139  \n",
       "11         1.140645  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data extraction for the summary\n",
    "data_info = {\n",
    "    'Data Name': [\"Vehicle\"] * len(optimizers),\n",
    "    'Data Size': [X_train.shape[0]] * len(optimizers),\n",
    "    'Number of Features': [X_train.shape[1]] * len(optimizers),\n",
    "    'Target Feature Type': [y_train.dtype] * len(optimizers),\n",
    "    'Neural Network Architecture': [\"CNN\"] * len(optimizers),\n",
    "    'Optimization Method': list(optimizers.keys())\n",
    "}\n",
    "\n",
    "# Extract results for each optimization method\n",
    "results_info = {\n",
    "    'Optimization Method': [],\n",
    "    'Test Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1-score': [],\n",
    "    'Convergence Speed': [],\n",
    "    'Training Time': [],\n",
    "    'Training Loss': [],\n",
    "    'Validation Loss': []\n",
    "}\n",
    "\n",
    "# Add the evaluation results for each optimizer\n",
    "for optimizer, result in results.items():\n",
    "    results_info['Optimization Method'].append(optimizer)\n",
    "    results_info['Test Accuracy'].append(result['test_accuracy'])\n",
    "    results_info['Precision'].append(result['precision'])\n",
    "    results_info['Recall'].append(result['recall'])\n",
    "    results_info['F1-score'].append(result['f1_score'])\n",
    "    results_info['Convergence Speed'].append(result['convergence_speed'])\n",
    "    results_info['Training Time'].append(result['training_time'])\n",
    "    results_info['Training Loss'].append(result['history'].history['loss'][0])\n",
    "    results_info['Validation Loss'].append(result['history'].history['val_loss'][0])\n",
    "\n",
    "# Create DataFrames and merge them for final results\n",
    "data_df = pd.DataFrame(data_info)\n",
    "results_df = pd.DataFrame(results_info)\n",
    "final_df = pd.merge(data_df, results_df, on='Optimization Method')\n",
    "\n",
    "# Show the final merged data\n",
    "final_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937ed403-6e1f-4778-9aec-1da8fdb4c7e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Loop through results to access each optimizer's training history\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optimizer_name, result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Retrieve the validation accuracy history for this optimizer\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhistory:\n\u001b[0;32m     11\u001b[0m         val_acc_history \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Test Accuracy per Optimizer per Epoch\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Loop through results to access each optimizer's training history\n",
    "for optimizer_name, result in results.items():\n",
    "    # Retrieve the validation accuracy history for this optimizer\n",
    "    if 'val_accuracy' in result['history'].history:\n",
    "        val_acc_history = result['history'].history['val_accuracy']\n",
    "    else:\n",
    "        # Sometimes the key might be 'val_acc', depending on TensorFlow version\n",
    "        val_acc_history = result['history'].history.get('val_acc', [])\n",
    "\n",
    "    # Plot the validation accuracy history\n",
    "    plt.plot(range(1, len(val_acc_history) + 1), val_acc_history, label=optimizer_name)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy per Optimizer per Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38fc22ac-ae95-4c00-ac79-1beec2085fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('Vehicle', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb6a38-6250-40ce-8f8d-41cdebe02941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed5f478-fb61-418c-8b55-0a435c050676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b6d54-1292-43a8-965f-01e8a0866835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
